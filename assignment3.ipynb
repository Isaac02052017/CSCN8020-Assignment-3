{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a740394-8522-4d1c-93a1-a0fb8d046315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cbd3c-dbcb-4c2e-af8d-20ba9d40bd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984aa1f9-416d-48ca-b722-0db738120543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[accept-rom-license,atari] in c:\\users\\srinu\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: autorom[accept-rom-license] in c:\\users\\srinu\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
      "Requirement already satisfied: ale_py>=0.9 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
      "Requirement already satisfied: click in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]) (8.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]) (2.32.2)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]) (0.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from click->autorom[accept-rom-license]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[atari,accept-rom-license] autorom[accept-rom-license]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687affea-85e7-4dab-ba0f-37385e2849d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\srinu\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\srinu\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\srinu\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\srinu\\anaconda3\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a9be72-3c2e-49c8-babb-a0a2ec1dce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\srinu\\anaconda3\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\srinu\\anaconda3\\lib\\site-packages (from gym) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ffba46-d686-4d70-a52e-62e8e7e5cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gym version: 0.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "print(\"Gym version:\", gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a644555-a7b4-4e0b-be71-63bc4c21e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run assignment3_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82671b-8bc7-4b0c-b9ed-7ee3dc97cc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6ca9a7-1474-4813-aa7c-e21d72640afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b92097b730>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) IMPORTS & CONFIG\n",
    "import random, collections, math, numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "import gymnasium as gym  # use classic 'gym' if you prefer; adjust reset/step returns\n",
    "\n",
    "# ---- your helper (placed in the same folder) ----\n",
    "from assignment3_utils import process_frame   # crop -> downsample -> grayscale -> normalize\n",
    "\n",
    "# -------------------------\n",
    "# GLOBAL CONFIG\n",
    "# -------------------------\n",
    "ENV_ID = \"PongDeterministic-v4\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "GAMMA = 0.95\n",
    "EPS_START = 1.0\n",
    "EPS_DECAY = 0.995\n",
    "EPS_MIN = 0.05\n",
    "\n",
    "BATCH_SIZE = 8             # (experiment: also try 16)\n",
    "TARGET_UPDATE_EP = 10      # (experiment: also try 3)\n",
    "LR = 1e-4\n",
    "REPLAY_CAPACITY = 100_000\n",
    "MIN_REPLAY_TO_LEARN = 20 * BATCH_SIZE\n",
    "\n",
    "STACK_N = 4\n",
    "FRAME_H, FRAME_W = 84, 80  # per your utils pipeline\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4116e-acff-4ddc-a606-59f441f042b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950d7228-6946-463c-be20-a92b64ee9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) FRAME STACKING HELPERS\n",
    "def make_initial_stack(env, image_shape=(FRAME_H, FRAME_W)):\n",
    "    obs, _ = env.reset(seed=SEED)\n",
    "    f = process_frame(obs, image_shape=image_shape)  # -> (1, H, W, 1)\n",
    "    f = f.squeeze(0).squeeze(-1)                     # -> (H, W)\n",
    "    stack = deque([f for _ in range(STACK_N)], maxlen=STACK_N)\n",
    "    return stack\n",
    "\n",
    "def append_frame(stack, obs, image_shape=(FRAME_H, FRAME_W)):\n",
    "    f = process_frame(obs, image_shape=image_shape)  # (1,H,W,1)\n",
    "    f = f.squeeze(0).squeeze(-1)                     # (H,W)\n",
    "    stack.append(f)\n",
    "\n",
    "def stack_to_tensor(stack):\n",
    "    s = np.stack(stack, axis=0)        # (4, H, W)\n",
    "    s = torch.from_numpy(s).float()    # float32\n",
    "    return s.to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3c344-993b-4049-a663-a352fccac761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b40594a-7a07-4c31-9f52-f68839776f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) REPLAY BUFFER\n",
    "Transition = collections.namedtuple(\"Transition\",\n",
    "    [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buf = collections.deque(maxlen=capacity)\n",
    "    def __len__(self):\n",
    "        return len(self.buf)\n",
    "    def push(self, *args):\n",
    "        self.buf.append(Transition(*args))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buf, batch_size)\n",
    "        return Transition(*zip(*batch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033327b-2073-472b-b79d-5d8e26a4c08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c99a97-e111-4512-9bf0-14821d4e0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) DQN MODEL\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(STACK_N, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),       nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),       nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # infer conv output size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, STACK_N, FRAME_H, FRAME_W)\n",
    "            conv_out = self.features(dummy).view(1, -1).shape[1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(conv_out, 512), nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        return self.head(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37894434-8a84-4ea3-995d-1d9b83b270e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c0eae4-d813-4568-8907-52c2bd2e2e7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3856864595.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 22\u001b[1;36m\u001b[0m\n\u001b[1;33m    return float(loss.item()\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# 6) TRAINING STEP\n",
    "def train_step(qnet, tgt, optimizer, replay, batch_size, gamma):\n",
    "    batch = replay.sample(batch_size)\n",
    "\n",
    "    state_batch = torch.stack(batch.state).to(DEVICE)       # (B, 4, 84, 80)\n",
    "    next_batch  = torch.stack(batch.next_state).to(DEVICE)  # (B, 4, 84, 80)\n",
    "    action_batch = torch.tensor(batch.action, device=DEVICE).long()   # (B,)\n",
    "    reward_batch = torch.tensor(batch.reward, device=DEVICE).float()  # (B,)\n",
    "    done_batch   = torch.tensor(batch.done,   device=DEVICE).float()  # (B,)\n",
    "\n",
    "    q_sa = qnet(state_batch).gather(1, action_batch.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_q_max = tgt(next_batch).max(dim=1)[0]\n",
    "        target = reward_batch + gamma * next_q_max * (1.0 - done_batch)\n",
    "\n",
    "    loss = nn.functional.smooth_l1_loss(q_sa, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(qnet.parameters(), 10.0)\n",
    "    optimizer.step()\n",
    "    return float(loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575f60f-2fbf-4386-9907-ebc81b195462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f139ba0-fbf4-4b46-9194-d1d7f6375159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) TRAINING LOOP\n",
    "def run_training(episodes=20, batch_size=BATCH_SIZE, target_update_ep=TARGET_UPDATE_EP,\n",
    "                 render=False):\n",
    "    env = gym.make(ENV_ID, render_mode=\"human\" if render else None)\n",
    "    num_actions = env.action_space.n\n",
    "\n",
    "    qnet = DQN(num_actions).to(DEVICE)\n",
    "    tgt  = DQN(num_actions).to(DEVICE)\n",
    "    tgt.load_state_dict(qnet.state_dict()); tgt.eval()\n",
    "\n",
    "    optimizer = optim.Adam(qnet.parameters(), lr=LR)\n",
    "    replay = ReplayBuffer(REPLAY_CAPACITY)\n",
    "\n",
    "    epsilon = EPS_START\n",
    "    scores, avg5, losses = [], [], []\n",
    "\n",
    "    for ep in range(1, episodes + 1):\n",
    "        stack = make_initial_stack(env)\n",
    "        state_t = stack_to_tensor(stack)\n",
    "        done = False\n",
    "        ep_reward = 0.0\n",
    "        ep_losses = []\n",
    "\n",
    "        while not done:\n",
    "            action = select_action(qnet, state_t, epsilon, num_actions)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            ep_reward += reward\n",
    "\n",
    "            append_frame(stack, obs)\n",
    "            next_t = stack_to_tensor(stack)\n",
    "\n",
    "            replay.push(state_t, action, reward, next_t, float(done))\n",
    "            state_t = next_t\n",
    "\n",
    "            if len(replay) >= max(MIN_REPLAY_TO_LEARN, batch_size):\n",
    "                ep_losses.append(train_step(qnet, tgt, optimizer, replay, batch_size, GAMMA))\n",
    "\n",
    "        epsilon = max(EPS_MIN, epsilon * EPS_DECAY)\n",
    "        if ep % target_update_ep == 0:\n",
    "            tgt.load_state_dict(qnet.state_dict())\n",
    "\n",
    "        scores.append(ep_reward)\n",
    "        avg5.append(np.mean(scores[-5:]))\n",
    "        losses.append(np.mean(ep_losses) if ep_losses else 0.0)\n",
    "\n",
    "        print(f\"Ep {ep:03d} | score={ep_reward:.1f} | avg5={avg5[-1]:.2f} | \"\n",
    "              f\"eps={epsilon:.3f} | loss={losses[-1]:.4f}\")\n",
    "\n",
    "    env.close()\n",
    "    return {\"scores\": scores, \"avg5\": avg5, \"losses\": losses, \"model\": qnet.state_dict()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98f0d2-e170-4d92-a803-7cdba467a24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e3d14-b49b-4273-b72d-ce1feb39c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) PLOTTING HELPERS\n",
    "def plot_metric(values, title, ylabel, xlabel=\"Episode\"):\n",
    "    plt.figure()\n",
    "    plt.plot(values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadece41-138e-4395-9d27-8c1b5f8e11ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbd3ba-5694-499c-b602-f475f8cffecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 10) SAVE RESULTS\n",
    "def save_results_csv(folder, name, scores, avg5, losses):\n",
    "    \"\"\"Save episode metrics to CSV for report inclusion.\"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    df = pd.DataFrame({\n",
    "        \"Episode\": range(1, len(scores)+1),\n",
    "        \"Score\": scores,\n",
    "        \"Avg5\": avg5,\n",
    "        \"Loss\": losses\n",
    "    })\n",
    "    csv_path = os.path.join(folder, f\"{name}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\" Results saved to {csv_path}\")\n",
    "\n",
    "def save_plot_png(folder, name, values, title, ylabel, xlabel=\"Episode\"):\n",
    "    \"\"\"Save metric plot as PNG.\"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    plt.figure()\n",
    "    plt.plot(values, label=ylabel)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    img_path = os.path.join(folder, f\"{name}.png\")\n",
    "    plt.savefig(img_path)\n",
    "    plt.close()\n",
    "    print(f\" Plot saved to {img_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79960d4-0a65-4ec6-88b2-fbf9a274047b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939dcad7-5db6-48f3-853f-833bf48e306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments():\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "    # ====== Baseline ======\n",
    "    print(\"\\n== Baseline: batch=8, target_update=10 ==\")\n",
    "    res_base = run_training(episodes=20, batch_size=8, target_update_ep=10)\n",
    "    save_results_csv(\"results\", \"baseline_b8_t10\", res_base[\"scores\"], res_base[\"avg5\"], res_base[\"losses\"])\n",
    "    save_plot_png(\"results\", \"baseline_b8_t10_score\", res_base[\"scores\"],\n",
    "                  \"Score per Episode (batch=8, target=10)\", \"Score\")\n",
    "    save_plot_png(\"results\", \"baseline_b8_t10_avg5\", res_base[\"avg5\"],\n",
    "                  \"Avg Reward (last 5) (batch=8, target=10)\", \"Avg(5) Reward\")\n",
    "\n",
    "    # ====== Batch Size Experiment ======\n",
    "    print(\"\\n== Batch Size Experiment: batch=16, target_update=10 ==\")\n",
    "    res_b16 = run_training(episodes=20, batch_size=16, target_update_ep=10)\n",
    "    save_results_csv(\"results\", \"batch16_t10\", res_b16[\"scores\"], res_b16[\"avg5\"], res_b16[\"losses\"])\n",
    "    save_plot_png(\"results\", \"batch16_t10_score\", res_b16[\"scores\"],\n",
    "                  \"Score per Episode (batch=16, target=10)\", \"Score\")\n",
    "    save_plot_png(\"results\", \"batch16_t10_avg5\", res_b16[\"avg5\"],\n",
    "                  \"Avg Reward (last 5) (batch=16, target=10)\", \"Avg(5) Reward\")\n",
    "\n",
    "    # ====== Target Update Experiment ======\n",
    "    print(\"\\n== Target Update Experiment: batch=8, target_update=3 ==\")\n",
    "    res_t3 = run_training(episodes=20, batch_size=8, target_update_ep=3)\n",
    "    save_results_csv(\"results\", \"batch8_t3\", res_t3[\"scores\"], res_t3[\"avg5\"], res_t3[\"losses\"])\n",
    "    save_plot_png(\"results\", \"batch8_t3_score\", res_t3[\"scores\"],\n",
    "                  \"Score per Episode (batch=8, target=3)\", \"Score\")\n",
    "    save_plot_png(\"results\", \"batch8_t3_avg5\", res_t3[\"avg5\"],\n",
    "                  \"Avg Reward (last 5) (batch=8, target=3)\", \"Avg(5) Reward\")\n",
    "\n",
    "    print(\"\\n All results saved under the 'results' folder!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd05ea-e2ea-4b5f-85b6-86e06595895d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f37a6-f6ea-4660-aff6-2bc625c7b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\R'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\R'\n",
      "C:\\Users\\srinu\\AppData\\Local\\Temp\\ipykernel_1740\\1570220878.py:13: SyntaxWarning: invalid escape sequence '\\R'\n",
      "  df_base = pd.read_csv(\"D:/2 Level\\Reinforcement/Assignment 3/Results/baseline_b8_t10.csv\")   # Default setup\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "#  TASK: Plot effects of deliberate parameter changes\n",
    "# =============================================================\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Step 1: Load the results from previous experiments\n",
    "# -------------------------------------------------------------\n",
    "# Make sure the CSV files are in your working directory\n",
    "df_base = pd.read_csv(\"D:/2 Level\\Reinforcement/Assignment 3/Results/baseline_b8_t10.csv\")   # Default setup\n",
    "df_b16 = pd.read_csv(\"D:/2 Level/Reinforcement/Assignment 3/Results/batch16_t10.csv\")        # Changing batch size\n",
    "df_t3 = pd.read_csv(\"D:/2 Level/Reinforcement/Assignment 3/Results/batch8_t3.csv\")           # Changing target update rate\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Step 2: Plot 1 — Effect of changing mini-batch size [8 → 16]\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# (a) Score per Episode\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(df_base[\"Episode\"], df_base[\"Score\"], label=\"Batch Size = 8 (Default)\", marker='o')\n",
    "plt.plot(df_b16[\"Episode\"], df_b16[\"Score\"], label=\"Batch Size = 16\", marker='x')\n",
    "plt.title(\"Effect of Changing Mini-Batch Size on Score per Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Score per Episode\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mini_batch_score_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# (b) Average Reward (Last 5 Episodes)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(df_base[\"Episode\"], df_base[\"Avg5\"], label=\"Batch Size = 8 (Default)\", marker='o')\n",
    "plt.plot(df_b16[\"Episode\"], df_b16[\"Avg5\"], label=\"Batch Size = 16\", marker='x')\n",
    "plt.title(\"Effect of Changing Mini-Batch Size on Average Cumulative Reward (Last 5 Episodes)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average Reward (5-Episode Window)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mini_batch_avg5_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Step 3: Plot 2 — Effect of changing target update rate [3 → 10]\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# (a) Score per Episode\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(df_base[\"Episode\"], df_base[\"Score\"], label=\"Target Update = 10 (Default)\", marker='o')\n",
    "plt.plot(df_t3[\"Episode\"], df_t3[\"Score\"], label=\"Target Update = 3\", marker='s')\n",
    "plt.title(\"Effect of Changing Target Update Rate on Score per Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Score per Episode\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"target_update_score_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# (b) Average Reward (Last 5 Episodes)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(df_base[\"Episode\"], df_base[\"Avg5\"], label=\"Target Update = 10 (Default)\", marker='o')\n",
    "plt.plot(df_t3[\"Episode\"], df_t3[\"Avg5\"], label=\"Target Update = 3\", marker='s')\n",
    "plt.title(\"Effect of Changing Target Update Rate on Average Cumulative Reward (Last 5 Episodes)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average Reward (5-Episode Window)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"target_update_avg5_comparison.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4e2b9-553c-4478-ad48-4e1bf20e931c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9770b3e-c1f7-4c66-bc9e-e2dfffae8330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385a5bc-e04c-4a15-9951-2bcc06985048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
